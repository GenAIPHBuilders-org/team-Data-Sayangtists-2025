{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Replace 'your_hf_token' with your actual Hugging Face access token\n",
    "login(token='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')\n",
    "\n",
    "# Change this to 70B if your system supports it\n",
    "model_id = \"google/gemma-3-4b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,  # or float16\n",
    "    device_map=\"auto\"            # automatically selects GPU\n",
    ")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_theme(text):\n",
    "    prompt = f\"\"\"You are a helpful assistant that summarizes content themes concisely.\n",
    "\n",
    "Given the following text, identify and return only one single word that best represents the main theme. Do not include any explanation or punctuation. Respond with **only** the one-word theme.\n",
    "\n",
    "Text:\n",
    "{text}\n",
    "\n",
    "Theme:\"\"\"\n",
    "\n",
    "    response = pipe(prompt, max_new_tokens=10, temperature=0.1)[0][\"generated_text\"]\n",
    "    theme = response.strip().split()[0]\n",
    "    print(f\"Raw response: {response}\")\n",
    "    return theme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brigadeiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
